# agg_std.yml
# Aggregation strategy for identifying variations and calculating the standard deviation of similarity across responses.

# meta: {"name": "name", "type": "string", "default": "", "example": "Std Answer ..."}
# name of the strategy
name: Std Aggregation

# meta: {"name": "description", "type": "string", "default": "", "example": ""}
# description of the strategy
description: >
    This strategy calculates the standard deviation of similarity between a given <sample> of texts or answers. 
    The goal is to measure the degree of variance between the texts, ranging from identical (low variance) 
    to highly divergent (high variance). The output is a JSON string that provides a standard deviation score 
    from 0 (virtually identical) to 6 (no commonalities), along with a short justification for the score.

# meta: {"name": "example", "type": "string", "default": "", "example": ""}
# example on how to precede when solving a task
example: >
    Example:
    Assume the following prompt or statement, "What happens when foxes meet dogs?". 
    We received the following responses.
      - "Response 1: The quick brown fox jumps over the lazy dog."
      - "Response 2: A fox swiftly leaps over a sleeping dog with grace and speed."
      - "Response 3: The nimble fox hops over a lethargic dog."
    Expected Output:
      {
        'std': 2, 
        'reasoning': 'The texts are similar in describing the same action but differ slightly in wording and emphasis on the dogâ€™s condition.'
      }
      
      In this case, the responses share a common theme but vary in their descriptions, leading to a moderate variance score of 2.

# meta: {"name": "task", "type": "string", "default": "", "example": ""}
# task to be performed
task: >
    Read and understand the following <sample> texts! Then, read and understand the provided 
    prompts or, (if no prompt was provided), re-construct the prompt or problem statement 
    based on the provided responses.
    Then, calculate the standard deviation of similarity between the texts, providing a 
    score from 0 (virtually identical) to 6 (no commonalities), along with a short justification 
    explaining the reasoning behind the chosen score. The output should be a JSON string in the 
    format {'std': <int>, 'reasoning': '<justification>'}.

# meta: {"name": "your_task", "type": "string", "default": "", "example": ""}
# your_task to be performed
your_task: >
    Using the provided RESPONSE SAMPLE`s, calculate a standard deviation score between 0 and 6 to 
    reflect the degree of similarity or variance. Include a brief justification for the score, 
    explaining how much the responses have in common or differ. The output should be in the 
    format: {'std': <int>, 'reasoning': '<justification_str>'}.
