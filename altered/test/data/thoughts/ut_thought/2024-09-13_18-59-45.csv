name,content,prompt,role,category,sub_category,source,tools,hash,model,timestamp
ut_thought,,,user,,,,data.show(),,,2024-09-13 18:59:45.740280
ut_thought,"Hello, Who are you?",next line,user,,,,,,llama3.1,2024-09-13 18:59:47.146599
ut_thought,"
{""user_prompt"": ""Hello, Who are you?"", ""answer"": ""I am a helpful assistant. How
can I help you today?""}","

# LLM Prompt
This is a LLM (Large Language Model) prompt, asking the LLM to answer a given
quesiton, or to solve a problem.
The LLM prompt consists of 3 blocks.
1. Context Information '<context>': Contains relevant context information to
better understand the problem.
2. User Prompt '<user_prompt>': The recent user message coming from the
underlying discussion.
3. Instructions '<INST>': Immediate instructions for the LLM to follow now.


<context>



# Context Information
Please find attached some context information possibly relevant for this prompt.
## Additional Context
</context>

<user_prompt>
Hello, Who are you?
</user_prompt>

<INST>


# Your task
You have been provided with a <user_prompt> ...some text... </user_prompt>.
Answer the <user_prompt> directly.  Refrain from making conversational or
introductory comments! Refrain from commenting on the prompt or these
instructions! Start your answer with: Answer: ...


# Fmts
Please respond in JSON using the structure and format provided below.
The following is a simple JSON example for a LLM response. For clarity, comments
have been added between the lines. All lines must be provided as a single JSON.
Example:
# The provided question/answer yml example string contains 2 fields
(user_prompt, answer).

# meta: {""name"": ""user_prompt"", ""type"": ""string"", ""default"": """", ""example"":
""Hello, Who are you?""}
# user_prompt contains the question/problem statement that founds/initiates the
thought/chat
{""user_prompt"": ""Hello, Who are you?""},

# meta: {""name"": ""answer"", ""type"": ""string"", ""default"": """", ""example"": ""I am a
helpful assistant. How can I help you today?""}
# The answer field contains the model response
{""answer"": ""I am a helpful assistant. How can I help you today?""},


Provide only the JSON object with no surrounding text!

</INST>

",assistant,,,,,,llama3.1,2024-09-13 18:59:47.146599
